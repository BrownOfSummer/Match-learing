{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                                                                 迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迁移学习的好处就在于，将训练好的模型当成特征提取器，然后加上简单的神经网络层，用很小的训练代价就可以得到很好的结果；这个文档是机遇inception-v3和Mobilenet来展开的；图像数据集准备：http://download.tensorflow.org/example_images/flower_photos.tgz 模型准备：inceptionv3 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'; 若要运行的是Mobilenet, 会自动根据'http://download.tensorflow.org/models/mobilenet_v1_' + version_string + '_' + size_string + '_frozen.tgz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当选择不变换图像时，会首先计算所有的bottlenecks，然后随机选取batch进行训练，这个过程还是比较快的；\n",
    "若选择进行图像变换，那么会对每次进行训练的batch进行图像变换然后计算bottlenecks，最后再进行训练；\n",
    "(1) 从原始模型得到的只有一个计算图和两个tensor：resized_image_tensor(输入)，bottleneck_tensor(输出)；\n",
    "(2) 一幅图像到bottleneck的转化func8：image_string_data ->feed-> jpeg_data_tensor(输入) -> decoded_image_tensor(输入) ->feed-> resized_image_tensor(模型输入) -> bottleneck_tensor(结果输出) -> bottleneck;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "子函数实现的功能：\n",
    "1. 把样本中所有的图片列表并按训练、验证、测试数据分开\n",
    "    create_image_lists(image_dir, testing_percentage, validation_percentage)；\n",
    "2. 定义函数通过类别名称、所属数据集和图片编号获取一张图片的地址。\n",
    "    get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "3. 定义函数生成模型处理之后的特征向量的文件地址。\n",
    "    get_bottleneck_path(image_lists, label_name, index, bottleneck_dir, category, architecture):\n",
    "4. 建立图模型。\n",
    "    create_model_graph(model_info):\n",
    "5. 定义函数使用加载的训练好的Inception-v3模型处理一张图片，得到这个图片的特征向量。\n",
    "    run_bottleneck_on_image(sess, image_data, image_data_tensor,decoded_image_tensor, resized_input_tensor,  bottleneck_tensor):\n",
    "6. 下载并解压文件。\n",
    "    maybe_download_and_extract(data_url):\n",
    "7. 确保一个folder存在。ensure_dir_exists(dir_name):\n",
    "8. 生成一个bottleneck并保存:\n",
    "    create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor):\n",
    "9. 若bottleneck存在则进行读取，若不存在或者读取错误则重新生成，调用了8;\n",
    "    get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture):\n",
    "10. 对所有的图像生成bottleneck，并按照bottleneck_path写入文件中，调用了9;\n",
    "   cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "      resized_input_tensor, bottleneck_tensor, architecture): \n",
    "11. 得到某一category的how_many个随机bottlenecks或者全部bottlenecks，是对10得到的众多结果读取;\n",
    "    get_random_cached_bottlenecks(sess, image_lists, how_many, category, bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "       decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture):\n",
    "12. 对于某一种category，先将图像进行变换再重新生成bottleneck，得到how_many个bottlenecks和ground_truths;\n",
    "    get_random_distorted_bottlenecks(sess, image_lists, how_many, category, image_dir, input_jpeg_tensor,\n",
    "    distorted_image, resized_input_tensor, bottleneck_tensor):\n",
    "13. 判断是否需要变换图像; should_distort_images(flip_left_right, random_crop, random_scale, random_brightness):\n",
    "14. 设计图像变化流程，返回placeholder和变换结果tensor;\n",
    "    add_input_distortions(flip_left_right, random_crop, random_scale,random_brightness, input_width, input_height,\n",
    "      input_depth, input_mean, input_std):\n",
    "15. 生成一个tensor的summary; variable_summaries(var):\n",
    "16. 定义分类层，返回分类层的重要op; \n",
    "    add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor, bottleneck_tensor_size):\n",
    "17. 定义函数对比预测值与ground_truth，返回准确率和预测值; add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "18. 将重新训练后的模型保存成二进制文件; save_graph_to_file(sess, graph, graph_file_name):\n",
    "19. 为summary准备路径; prepare_file_system():\n",
    "20. 输入模型名称，返回模型的信息; create_model_info(architecture):\n",
    "21. 根据模型信息预处理图像; add_jpeg_decoding(input_width, input_height, input_depth, input_mean, input_std):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 把样本中所有的图片列表并按训练、验证、测试数据分开"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和1.0 book中的函数功能是类似的，最终的目的是实现一个dictionary, 输入正整数的两个百分比，然后将每一类的图像进行划分\n",
    "result = \n",
    "{\n",
    "    \"rose\":{\n",
    "              'dir': roses,\n",
    "              'training': [1.jpg, 2.jpeg, 64.JPG, 83.JPEG, .....],\n",
    "              'testing': [43.jpg, 93.jpeg, lala.JPG, haha.JPEG],\n",
    "              'validation': [some image names....],\n",
    "           }\n",
    "    \"sunflowers\":{\n",
    "              'dir':sunflowers,\n",
    "              'training':[]\n",
    "              'testing':[]\n",
    "              'validation':[]\n",
    "              }\n",
    "\n",
    "    ......\n",
    "}\n",
    "得到上述的字典结构，其中result={\"label1\":{'dir':rose, }, ...}；label部分可能与子文件夹名称不同，但是dir部分是相同不变的；\n",
    "不同之处：没有采用0~100随机数的方法来进行图像分类，而是采用的hashlib的方法，定义了最大hash值，然后进行的划分，结果是相同的\n",
    "返回：result dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all parameters that are tied to the particular model architecture\n",
    "# we're using for Inception v3. These include things like tensor names and their\n",
    "# sizes. If you want to adapt this script to work with another model, you will\n",
    "# need to update these to reflect the values in the network you're using.\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
    "\n",
    "\n",
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "  \"\"\"Builds a list of training images from the file system.\n",
    "  Analyzes the sub folders in the image directory, splits them into stable\n",
    "  training, testing, and validation sets, and returns a data structure\n",
    "  describing the lists of images for each label and their paths.\n",
    "  Args:\n",
    "    image_dir: String path to a folder containing subfolders of images.\n",
    "    testing_percentage: Integer percentage of the images to reserve for tests.\n",
    "    validation_percentage: Integer percentage of images reserved for validation.\n",
    "  Returns:\n",
    "    A dictionary containing an entry for each label subfolder, with images split\n",
    "    into training, testing, and validation sets within each label.\n",
    "  \"\"\"\n",
    "  if not gfile.Exists(image_dir):\n",
    "    tf.logging.error(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "    return None\n",
    "  result = {}\n",
    "  sub_dirs = [x[0] for x in gfile.Walk(image_dir)]\n",
    "  # The root directory comes first, so skip it.\n",
    "  is_root_dir = True\n",
    "  for sub_dir in sub_dirs:\n",
    "    if is_root_dir:\n",
    "      is_root_dir = False\n",
    "      continue\n",
    "    extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "    file_list = []\n",
    "    dir_name = os.path.basename(sub_dir)\n",
    "    if dir_name == image_dir:\n",
    "      continue\n",
    "    tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")\n",
    "    for extension in extensions:\n",
    "      file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "      file_list.extend(gfile.Glob(file_glob))\n",
    "    if not file_list:\n",
    "      tf.logging.warning('No files found')\n",
    "      continue\n",
    "    if len(file_list) < 20:\n",
    "      tf.logging.warning(\n",
    "          'WARNING: Folder has less than 20 images, which may cause issues.')\n",
    "    elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "      tf.logging.warning(\n",
    "          'WARNING: Folder {} has more than {} images. Some images will '\n",
    "          'never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "    label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "    training_images = []\n",
    "    testing_images = []\n",
    "    validation_images = []\n",
    "    for file_name in file_list:\n",
    "      base_name = os.path.basename(file_name)\n",
    "      # We want to ignore anything after '_nohash_' in the file name when\n",
    "      # deciding which set to put an image in, the data set creator has a way of\n",
    "      # grouping photos that are close variations of each other. For example\n",
    "      # this is used in the plant disease data set to group multiple pictures of\n",
    "      # the same leaf.\n",
    "      hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "      # This looks a bit magical, but we need to decide whether this file should\n",
    "      # go into the training, testing, or validation sets, and we want to keep\n",
    "      # existing files in the same set even if more files are subsequently\n",
    "      # added.\n",
    "      # To do that, we need a stable way of deciding based on just the file name\n",
    "      # itself, so we do a hash of that and then use that to generate a\n",
    "      # probability value that we use to assign it.\n",
    "      hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "      percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                          (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n",
    "                         (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "      if percentage_hash < validation_percentage:\n",
    "        validation_images.append(base_name)\n",
    "      elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        testing_images.append(base_name)\n",
    "      else:\n",
    "        training_images.append(base_name)\n",
    "    result[label_name] = {\n",
    "        'dir': dir_name,\n",
    "        'training': training_images,\n",
    "        'testing': testing_images,\n",
    "        'validation': validation_images,\n",
    "    }\n",
    "  return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义函数通过类别名称、所属数据集和图片编号获取一张图片的地址。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#def get_image_path(image_lists, image_dir, label_name, index, category):\n",
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "    这个函数的作用就是根据上述的result，也就是参数中的image_lists，图像的存储路径image_dir:/path/flower_photos；标签名称label_name: roses, sunflowers等； category: training, or testing,or validation; index: 具体的索引下标; 来唯一的获取一张图片\n",
    "也就是将image_lists中存储的路径，结合image_dir的路径，并根据index来唯一索引到一张图片；\n",
    "    image_list -> result\n",
    "    label_name -> roeses, or sunflowers...\n",
    "    index -> number\n",
    "    image_dir -> /path/flower_photos\n",
    "    category -> training, or testing, or validation\n",
    "返回：一张图像的完整路径；\n",
    "上面是book中的函数参数，这个函数的功能是一致的，根据输入的label_name, 整数的index，image_dir, 训练模式category返回一幅图像的绝对路径；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "  \"\"\"\"Returns a path to an image for a label at the given index.\n",
    "  Args:\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    label_name: Label string we want to get an image for.\n",
    "    index: Int offset of the image we want. This will be moduloed by the\n",
    "    available number of images for the label, so it can be arbitrarily large.\n",
    "    image_dir: Root folder string of the subfolders containing the training\n",
    "    images.\n",
    "    category: Name string of set to pull images from - training, testing, or\n",
    "    validation.\n",
    "  Returns:\n",
    "    File system path string to an image that meets the requested parameters.\n",
    "  \"\"\"\n",
    "  if label_name not in image_lists:\n",
    "    tf.logging.fatal('Label does not exist %s.', label_name)\n",
    "  label_lists = image_lists[label_name]\n",
    "  if category not in label_lists:\n",
    "    tf.logging.fatal('Category does not exist %s.', category)\n",
    "  category_list = label_lists[category]\n",
    "  if not category_list:\n",
    "    tf.logging.fatal('Label %s has no images in the category %s.',\n",
    "                     label_name, category)\n",
    "  mod_index = index % len(category_list)\n",
    "  base_name = category_list[mod_index]\n",
    "  sub_dir = label_lists['dir']\n",
    "  full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "  return full_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 定义函数生成模型处理之后的特征向量的文件地址。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir, category, architecture):\n",
    "  return get_image_path(image_lists, label_name, index, bottleneck_dir, category) + '_' + architecture + '.txt'\n",
    "    将模型的输出当成了特征提取过程，每个图像都会得到一个特征向量，保存成与图像名对应的txt文件：image-name.jpg_modelname.txt\n",
    "    image_lists: 1中得到的图像的名称，位置，分类等信息的字典；\n",
    "    label_name: 每一类的名称roses, sunflowers....\n",
    "    index: 每一类下的某一张图像索引；\n",
    "    bottleneck_dir: 保存特征向量的根路径；\n",
    "    category: training, testing, validation\n",
    "    architecture：由于可以训练inception-v3或者别的不同Mobilenet, 这里加了这个作为区分；\n",
    "    首先根据image_list, label_name, inxex, category来得到: label_name/image-name.jpg;\n",
    "    然后根据bottleneck_dir生成：bottleneck_dir/labe_name/image-name.jpg_inception_v3.txt\n",
    "    返回：一个txt文件的路径名称；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir,\n",
    "                        category, architecture):\n",
    "  \"\"\"\"Returns a path to a bottleneck file for a label at the given index.\n",
    "  Args:\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    label_name: Label string we want to get an image for.\n",
    "    index: Integer offset of the image we want. This will be moduloed by the\n",
    "    available number of images for the label, so it can be arbitrarily large.\n",
    "    bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "    category: Name string of set to pull images from - training, testing, or\n",
    "    validation.\n",
    "    architecture: The name of the model architecture.\n",
    "  Returns:\n",
    "    File system path string to an image that meets the requested parameters.\n",
    "  \"\"\"\n",
    "  return get_image_path(image_lists, label_name, index, bottleneck_dir,\n",
    "                        category) + '_' + architecture + '.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 建立图模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据输入的model_info生成一个graph，并返回graph和两个tensor；\n",
    "输入：model_info 保存了图像的结构信息；\n",
    "返回：包含已训练模型的网络，和两个tensor：bottleneck_tensor, resized_input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_graph(model_info):\n",
    "  \"\"\"\"Creates a graph from saved GraphDef file and returns a Graph object.\n",
    "  Args:\n",
    "    model_info: Dictionary containing information about the model architecture.\n",
    "  Returns:\n",
    "    Graph holding the trained Inception network, and various tensors we'll be\n",
    "    manipulating.\n",
    "  \"\"\"\n",
    "  with tf.Graph().as_default() as graph:\n",
    "    model_path = os.path.join(FLAGS.model_dir, model_info['model_file_name'])\n",
    "    with gfile.FastGFile(model_path, 'rb') as f:\n",
    "      graph_def = tf.GraphDef()\n",
    "      graph_def.ParseFromString(f.read())\n",
    "      bottleneck_tensor, resized_input_tensor = (tf.import_graph_def(\n",
    "          graph_def,\n",
    "          name='',\n",
    "          return_elements=[\n",
    "              model_info['bottleneck_tensor_name'],\n",
    "              model_info['resized_input_tensor_name'],\n",
    "          ]))\n",
    "  return graph, bottleneck_tensor, resized_input_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 定义函数使用加载的训练好的Inception-v3模型处理一张图片，得到这个图片的特征向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用模型的bottleneck层对输入的图像计算特征，返回计算好的特征向量；\n",
    "image_data: 输入图像,gfile读取image得到的string文件；\n",
    "image_data_tensor: 定义好的placeholder，图中的的数据输入层；\n",
    "decoded_image_tensor: 输出改变尺寸和预处理之后的op；\n",
    "resized_input_tensor: placeholder, 接受上述decoded之后的图像tensor\n",
    "bottleneck_tensor: 原图中的bottleneck层，softmax之前的层；\n",
    "返回：计算得到的特征向量bottleneck_values;\n",
    "image_string_data ->feed-> jpeg_data_tensor(image_data_tensor) -> decoded_image_tensor ->feed-> resized_image_tensor \n",
    "-> bottleneck_tensor -> bottleneck;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor,\n",
    "                            decoded_image_tensor, resized_input_tensor,\n",
    "                            bottleneck_tensor):\n",
    "  \"\"\"Runs inference on an image to extract the 'bottleneck' summary layer.\n",
    "  Args:\n",
    "    sess: Current active TensorFlow Session.\n",
    "    image_data: String of raw JPEG data.\n",
    "    image_data_tensor: Input data layer in the graph.\n",
    "    decoded_image_tensor: Output of initial image resizing and  preprocessing.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: Layer before the final softmax.\n",
    "  Returns:\n",
    "    Numpy array of bottleneck values.\n",
    "  \"\"\"\n",
    "  # First decode the JPEG image, resize it, and rescale the pixel values.\n",
    "  resized_input_values = sess.run(decoded_image_tensor,\n",
    "                                  {image_data_tensor: image_data})\n",
    "  # Then run it through the recognition network.\n",
    "  bottleneck_values = sess.run(bottleneck_tensor,\n",
    "                               {resized_input_tensor: resized_input_values})\n",
    "  bottleneck_values = np.squeeze(bottleneck_values)\n",
    "  return bottleneck_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 下载并解压文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先判断需要的训练好的模型是否在路径中，若没有则从url上download；\n",
    "输入：data_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'; 是保存在model info中的，\n",
    "同时，若要运行的是Mobilenet, 会自动根据data_url = 'http://download.tensorflow.org/models/mobilenet_v1_' + version_string + '_' + size_string + '_frozen.tgz'\n",
    "来自动生成Mobile的下载路径；\n",
    "默认模型保存文件夹：/tmp/imagenet；\n",
    "默认模型路径：/tmp/imagenet/inception-2015-12-05.tgz 或跟上Mobilenet；\n",
    "若默认路径不存在则进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download_and_extract(data_url):\n",
    "  \"\"\"Download and extract model tar file.\n",
    "  If the pretrained model we're using doesn't already exist, this function\n",
    "  downloads it from the TensorFlow.org website and unpacks it into a directory.\n",
    "  Args:\n",
    "    data_url: Web location of the tar file containing the pretrained model.\n",
    "  \"\"\"\n",
    "  dest_directory = FLAGS.model_dir #/tmp/imagenet, change with --model_dir some_dir\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = data_url.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                       (filename,\n",
    "                        float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    tf.logging.info('Successfully downloaded', filename, statinfo.st_size,\n",
    "                    'bytes.')\n",
    "  tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 确保一个folder存在"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入一个direcotry名称，若不存在则mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensure_dir_exists(dir_name):\n",
    "  \"\"\"Makes sure the folder exists on disk.\n",
    "  Args:\n",
    "    dir_name: Path string to the folder we want to create.\n",
    "  \"\"\"\n",
    "  if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 生成一个bottleneck并保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bottleneck_path: 要保存的bottleneck的txt文件路径，可通过get_bottleneck_path获取；\n",
    "image_list: 图像dictionary；\n",
    "label_name: 用来在image_list中索引某一类；\n",
    "category: 用来在某一类中确定是training, testing, validation等；\n",
    "index: 用来在training, testing, validation数据集中确定是某一张图像；\n",
    "image_dir: /path/to/flower_pthoto;\n",
    "sess:\n",
    "jpeg_data_tensor: 也即image_data_tensor, placeholder for image gfile string;\n",
    "decoded_image_tensor: decode, resize, rescale op;\n",
    "resized_input_tensor: placeholder for the output of decoded_image_tensor；\n",
    "bottleneck_tensor: 计算得到的特征向量；\n",
    "注意的是，这里并没有返回值，直接写入了文件，所以这个版本的操作是分成两部分进行的，先生成所有的文件，然后再进行训练；\n",
    "\n",
    "image_string_data ->feed-> jpeg_data_tensor -> decoded_image_tensor ->feed-> resized_image_tensor -> bottleneck_tensor -> bottleneck;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           decoded_image_tensor, resized_input_tensor,\n",
    "                           bottleneck_tensor):\n",
    "  \"\"\"Create a single bottleneck file.\"\"\"\n",
    "  tf.logging.info('Creating bottleneck at ' + bottleneck_path)\n",
    "  image_path = get_image_path(image_lists, label_name, index,\n",
    "                              image_dir, category)\n",
    "  if not gfile.Exists(image_path):\n",
    "    tf.logging.fatal('File does not exist %s', image_path)\n",
    "  image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "  try:\n",
    "    bottleneck_values = run_bottleneck_on_image(\n",
    "        sess, image_data, jpeg_data_tensor, decoded_image_tensor,\n",
    "        resized_input_tensor, bottleneck_tensor)\n",
    "  except Exception as e:\n",
    "    raise RuntimeError('Error during processing file %s (%s)' % (image_path,\n",
    "                                                                 str(e)))\n",
    "  bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "  with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "    bottleneck_file.write(bottleneck_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 若bottleneck存在则进行读取，若不存在或者读取错误则重新生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数调用get_bottleneck_path获取bottleneck文件路径，当文件不存在或者读取错误时重新生成文件create_bottleneck_file; 注意的是这个函数是得到一个bottleneck 特征向量；\n",
    "一个原始图像到bottleneck的流程是：\n",
    "image_string_data ->feed-> jpeg_data_tensor -> decoded_image_tensor ->feed-> resized_image_tensor -> bottleneck_tensor -> bottleneck;\n",
    "其中，在jpeg_data_tensor计算得到decoded_image_tensor的时候会将图像resize成模型需要的resized_image_tensor尺寸大小；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir,\n",
    "                             category, bottleneck_dir, jpeg_data_tensor,\n",
    "                             decoded_image_tensor, resized_input_tensor,\n",
    "                             bottleneck_tensor, architecture):\n",
    "  \"\"\"Retrieves or calculates bottleneck values for an image.\n",
    "  If a cached version of the bottleneck data exists on-disk, return that,\n",
    "  otherwise calculate the data and save it to disk for future use.\n",
    "  Args:\n",
    "    sess: The current active TensorFlow Session.\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    label_name: Label string we want to get an image for.\n",
    "    index: Integer offset of the image we want. This will be modulo-ed by the\n",
    "    available number of images for the label, so it can be arbitrarily large.\n",
    "    image_dir: Root folder string  of the subfolders containing the training\n",
    "    images.\n",
    "    category: Name string of which  set to pull images from - training, testing,\n",
    "    or validation.\n",
    "    bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "    jpeg_data_tensor: The tensor to feed loaded jpeg data into.\n",
    "    decoded_image_tensor: The output of decoding and resizing the image.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: The output tensor for the bottleneck values.\n",
    "    architecture: The name of the model architecture.\n",
    "  Returns:\n",
    "    Numpy array of values produced by the bottleneck layer for the image.\n",
    "  \"\"\"\n",
    "  label_lists = image_lists[label_name]\n",
    "  sub_dir = label_lists['dir']\n",
    "  sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n",
    "  ensure_dir_exists(sub_dir_path)\n",
    "  bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\n",
    "                                        bottleneck_dir, category, architecture)\n",
    "  if not os.path.exists(bottleneck_path):\n",
    "    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           decoded_image_tensor, resized_input_tensor,\n",
    "                           bottleneck_tensor)\n",
    "  with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "    bottleneck_string = bottleneck_file.read()\n",
    "  did_hit_error = False\n",
    "  try:\n",
    "    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "  except ValueError:\n",
    "    tf.logging.warning('Invalid float found, recreating bottleneck')\n",
    "    did_hit_error = True\n",
    "  if did_hit_error:\n",
    "    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           decoded_image_tensor, resized_input_tensor,\n",
    "                           bottleneck_tensor)\n",
    "    with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "      bottleneck_string = bottleneck_file.read()\n",
    "    # Allow exceptions to propagate here, since they shouldn't happen after a\n",
    "    # fresh creation\n",
    "    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "  return bottleneck_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 对所有的图像生成bottleneck，并按照bottleneck_path写入文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算bottleneck特征向量是十分耗时的，训练的过程中需要多次用到所有的特征向量，每次都重新生成显然是不合适的；可选的做法是，将所有的特征向量一次生成，然后在训练的过程中多次读取；这个函数的功能就是遍历所有的图像，计算得到特征向量，并保存。\n",
    "image_list: dictionary for all image.\n",
    "image_dir: /path/to/flower_photos；\n",
    "bottleneck_dir: 保存特征向量的根路径；\n",
    "其余参数看代码解释；\n",
    "执行过程：根据image_list得到文件路径结构，对于每一类，每一类中的training, testing, validation都生成feature vector保存；得到如下结构：\n",
    "/tmp/bottleneck/：daisy  dandelion  roses  sunflowers  tulips；\n",
    "这里有疑问的是，只传入了一个bottleneck_dir，就计算了所有的特征向量，是如何分成不同的字文件夹的？\n",
    "答案：在get_or_create_bottleneck中生成之前会判断sub_dir是否存在；\n",
    "一个原始图像到bottleneck的流程是：\n",
    "image_string_data ->feed-> jpeg_data_tensor -> decoded_image_tensor ->feed-> resized_image_tensor -> bottleneck_tensor -> bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir,\n",
    "                      jpeg_data_tensor, decoded_image_tensor,\n",
    "                      resized_input_tensor, bottleneck_tensor, architecture):\n",
    "  \"\"\"Ensures all the training, testing, and validation bottlenecks are cached.\n",
    "  Because we're likely to read the same image multiple times (if there are no\n",
    "  distortions applied during training) it can speed things up a lot if we\n",
    "  calculate the bottleneck layer values once for each image during\n",
    "  preprocessing, and then just read those cached values repeatedly during\n",
    "  training. Here we go through all the images we've found, calculate those\n",
    "  values, and save them off.\n",
    "  Args:\n",
    "    sess: The current active TensorFlow Session.\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    image_dir: Root folder string of the subfolders containing the training\n",
    "    images.\n",
    "    bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "    jpeg_data_tensor: Input tensor for jpeg data from file.\n",
    "    decoded_image_tensor: The output of decoding and resizing the image.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: The penultimate output layer of the graph.\n",
    "    architecture: The name of the model architecture.\n",
    "  Returns:\n",
    "    Nothing.\n",
    "这里有疑问的是，只传入了一个bottleneck_dir，就计算了所有的特征向量，是如何分成不同的字文件夹的？\n",
    "  \"\"\"\n",
    "  how_many_bottlenecks = 0\n",
    "  ensure_dir_exists(bottleneck_dir) # if not, mkdir\n",
    "  for label_name, label_lists in image_lists.items(): #label_name: different classes, label_lists: contents\n",
    "    for category in ['training', 'testing', 'validation']:\n",
    "      category_list = label_lists[category]\n",
    "      for index, unused_base_name in enumerate(category_list):\n",
    "        # get_or_create_bottleneck 函数中ensure_dir_exists(sub_dir_path)保证了每个子folder的存在\n",
    "        get_or_create_bottleneck(\n",
    "            sess, image_lists, label_name, index, image_dir, category,\n",
    "            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "            resized_input_tensor, bottleneck_tensor, architecture)\n",
    "\n",
    "        how_many_bottlenecks += 1\n",
    "        if how_many_bottlenecks % 100 == 0:\n",
    "          tf.logging.info(\n",
    "              str(how_many_bottlenecks) + ' bottleneck files created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 得到某一category的how_many个随机bottlenecks或者全部bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数的功能主要是从cache_bottlenecks中生成好的bottlenecks中提取出某一个category的一部分或者全部；\n",
    "这里需要注意的是，参数中指定了how_many和category；category指定了读取training, testing还是validation；how_many>=0需要读取how_many个，至于是某个label_name类别中的category，以及是某个category中的某一幅图像图像都是随机的；当how_many< 0时，全部读取所有label_name中的指定category；这么做的好处就是training的时候当作batch用，testing的时候全部读取；\n",
    "返回：读取的bottlenecks，与之对应的ground_truths，与之对应的图像名称filenames；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_cached_bottlenecks(sess, image_lists, how_many, category,\n",
    "                                  bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "                                  decoded_image_tensor, resized_input_tensor,\n",
    "                                  bottleneck_tensor, architecture):\n",
    "  \"\"\"Retrieves bottleneck values for cached images.\n",
    "  If no distortions are being applied, this function can retrieve the cached\n",
    "  bottleneck values directly from disk for images. It picks a random set of\n",
    "  images from the specified category.\n",
    "  Args:\n",
    "    sess: Current TensorFlow Session.\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    how_many: If positive, a random sample of this size will be chosen.\n",
    "    If negative, all bottlenecks will be retrieved.\n",
    "    category: Name string of which set to pull from - training, testing, or\n",
    "    validation.\n",
    "    bottleneck_dir: Folder string holding cached files of bottleneck values.\n",
    "    image_dir: Root folder string of the subfolders containing the training\n",
    "    images.\n",
    "    下面的tensor在需要生成bottleneck时用得到\n",
    "    jpeg_data_tensor: The layer to feed jpeg image data into.\n",
    "    decoded_image_tensor: The output of decoding and resizing the image.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: The bottleneck output layer of the CNN graph.\n",
    "    architecture: The name of the model architecture.\n",
    "  Returns:\n",
    "    List of bottleneck arrays, their corresponding ground truths, and the\n",
    "    relevant filenames.\n",
    "  \"\"\"\n",
    "  class_count = len(image_lists.keys())\n",
    "  bottlenecks = []\n",
    "  ground_truths = []\n",
    "  filenames = []\n",
    "  if how_many >= 0:\n",
    "    # Retrieve a random sample of bottlenecks.\n",
    "    for unused_i in range(how_many):\n",
    "      label_index = random.randrange(class_count)\n",
    "      label_name = list(image_lists.keys())[label_index] #random label class\n",
    "      image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "      image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                  image_dir, category) #random image_name in this category\n",
    "      bottleneck = get_or_create_bottleneck(\n",
    "          sess, image_lists, label_name, image_index, image_dir, category,\n",
    "          bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "          resized_input_tensor, bottleneck_tensor, architecture)\n",
    "      ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "      ground_truth[label_index] = 1.0\n",
    "      bottlenecks.append(bottleneck)\n",
    "      ground_truths.append(ground_truth)\n",
    "      filenames.append(image_name)\n",
    "  else:\n",
    "    # Retrieve all bottlenecks.\n",
    "    for label_index, label_name in enumerate(image_lists.keys()):\n",
    "      for image_index, image_name in enumerate(\n",
    "          image_lists[label_name][category]):\n",
    "        image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                    image_dir, category)\n",
    "        bottleneck = get_or_create_bottleneck(\n",
    "            sess, image_lists, label_name, image_index, image_dir, category,\n",
    "            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "            resized_input_tensor, bottleneck_tensor, architecture)\n",
    "        ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "        ground_truth[label_index] = 1.0\n",
    "        bottlenecks.append(bottleneck)\n",
    "        ground_truths.append(ground_truth)\n",
    "        filenames.append(image_name)\n",
    "  return bottlenecks, ground_truths, filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 对于某一种category，先将图像进行变换再重新生成bottleneck，得到how_many个bottlenecks和ground_truths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们用变换后的图像(裁减，缩放，翻转)做训练时，我们需要对每幅图像重新计算，不能应用计算好的cached bottleneck；\n",
    "这里多出了distored_image，首先input_jpeg_tensor作为input placeholder传入读取的图像；其次，用distored_image op对图像进行变换；再次，对变换后的图像进行bottleneck生成；最后组合成bottlenecks和ground_truths返回；整体的过程相当于，对于某一种category，随机选取某一个label_name中的一幅图像，进行图像变换，生成bottleneck和ground_truth;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_distorted_bottlenecks(\n",
    "    sess, image_lists, how_many, category, image_dir, input_jpeg_tensor,\n",
    "    distorted_image, resized_input_tensor, bottleneck_tensor):\n",
    "  \"\"\"Retrieves bottleneck values for training images, after distortions.\n",
    "  If we're training with distortions like crops, scales, or flips, we have to\n",
    "  recalculate the full model for every image, and so we can't use cached\n",
    "  bottleneck values. Instead we find random images for the requested category,\n",
    "  run them through the distortion graph, and then the full graph to get the\n",
    "  bottleneck results for each.\n",
    "  Args:\n",
    "    sess: Current TensorFlow Session.\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    how_many: The integer number of bottleneck values to return.\n",
    "    category: Name string of which set of images to fetch - training, testing,\n",
    "    or validation.\n",
    "    image_dir: Root folder string of the subfolders containing the training\n",
    "    images.\n",
    "    input_jpeg_tensor: The input layer we feed the image data to.\n",
    "    distorted_image: The output node of the distortion graph.\n",
    "    resized_input_tensor: The input node of the recognition graph.\n",
    "    bottleneck_tensor: The bottleneck output layer of the CNN graph.\n",
    "  Returns:\n",
    "    List of bottleneck arrays and their corresponding ground truths.\n",
    "  \"\"\"\n",
    "  class_count = len(image_lists.keys())\n",
    "  bottlenecks = []\n",
    "  ground_truths = []\n",
    "  for unused_i in range(how_many):\n",
    "    label_index = random.randrange(class_count)\n",
    "    label_name = list(image_lists.keys())[label_index]\n",
    "    image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "    image_path = get_image_path(image_lists, label_name, image_index, image_dir,\n",
    "                                category)\n",
    "    if not gfile.Exists(image_path):\n",
    "      tf.logging.fatal('File does not exist %s', image_path)\n",
    "    jpeg_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "    # Note that we materialize the distorted_image_data as a numpy array before\n",
    "    # sending running inference on the image. This involves 2 memory copies and\n",
    "    # might be optimized in other implementations.\n",
    "    distorted_image_data = sess.run(distorted_image,\n",
    "                                    {input_jpeg_tensor: jpeg_data})\n",
    "    bottleneck_values = sess.run(bottleneck_tensor,\n",
    "                                 {resized_input_tensor: distorted_image_data})\n",
    "    bottleneck_values = np.squeeze(bottleneck_values)\n",
    "    ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "    ground_truth[label_index] = 1.0\n",
    "    bottlenecks.append(bottleneck_values)\n",
    "    ground_truths.append(ground_truth)\n",
    "  return bottlenecks, ground_truths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. 判断是否需要变换图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若左右翻转为true，或者crop box中的边界百分比不为0，或者缩放的百分比不为0，或者亮度变化的百分比不为0，则需要变换，否则不需要；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def should_distort_images(flip_left_right, random_crop, random_scale,\n",
    "                          random_brightness):\n",
    "  \"\"\"Whether any distortions are enabled, from the input flags.\n",
    "  Args:\n",
    "    flip_left_right: Boolean whether to randomly mirror images horizontally.\n",
    "    random_crop: Integer percentage setting the total margin used around the\n",
    "    crop box.\n",
    "    random_scale: Integer percentage of how much to vary the scale by.\n",
    "    random_brightness: Integer range to randomly multiply the pixel values by.\n",
    "  Returns:\n",
    "    Boolean value indicating whether any distortions should be applied.\n",
    "  \"\"\"\n",
    "  return (flip_left_right or (random_crop != 0) or (random_scale != 0) or\n",
    "          (random_brightness != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. 设计图像变化流程，返回placeholder和变换结果tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对图像进行随机变换，包括左右翻转，裁减，缩放等；返回一个接收图像string的placeholder和一个变换后的结果tensor。\n",
    "这里的input_width, input_height, input_depth, input_mean, input_std都来自于模型model_info，在做完图像变换后返回的图像tensor是模型计算bottleneck所需要的尺寸(类似于21 add_jpeg_decoding函数所做的部分)，inception_v3是[229,229,3]；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_input_distortions(flip_left_right, random_crop, random_scale,\n",
    "                          random_brightness, input_width, input_height,\n",
    "                          input_depth, input_mean, input_std):\n",
    "  \"\"\"Creates the operations to apply the specified distortions.\n",
    "  During training it can help to improve the results if we run the images\n",
    "  through simple distortions like crops, scales, and flips. These reflect the\n",
    "  kind of variations we expect in the real world, and so can help train the\n",
    "  model to cope with natural data more effectively. Here we take the supplied\n",
    "  parameters and construct a network of operations to apply them to an image.\n",
    "  Cropping\n",
    "  ~~~~~~~~\n",
    "  Cropping is done by placing a bounding box at a random position in the full\n",
    "  image. The cropping parameter controls the size of that box relative to the\n",
    "  input image. If it's zero, then the box is the same size as the input and no\n",
    "  cropping is performed. If the value is 50%, then the crop box will be half the\n",
    "  width and height of the input. In a diagram it looks like this:\n",
    "  <       width         >\n",
    "  +---------------------+\n",
    "  |                     |\n",
    "  |   width - crop%     |\n",
    "  |    <      >         |\n",
    "  |    +------+         |\n",
    "  |    |      |         |\n",
    "  |    |      |         |\n",
    "  |    |      |         |\n",
    "  |    +------+         |\n",
    "  |                     |\n",
    "  |                     |\n",
    "  +---------------------+\n",
    "  Scaling\n",
    "  ~~~~~~~\n",
    "  Scaling is a lot like cropping, except that the bounding box is always\n",
    "  centered and its size varies randomly within the given range. For example if\n",
    "  the scale percentage is zero, then the bounding box is the same size as the\n",
    "  input and no scaling is applied. If it's 50%, then the bounding box will be in\n",
    "  a random range between half the width and height and full size.\n",
    "  Args:\n",
    "    flip_left_right: Boolean whether to randomly mirror images horizontally.\n",
    "    random_crop: Integer percentage setting the total margin used around the\n",
    "    crop box.\n",
    "    random_scale: Integer percentage of how much to vary the scale by.\n",
    "    random_brightness: Integer range to randomly multiply the pixel values by.\n",
    "    graph.\n",
    "    input_width: Horizontal size of expected input image to model.\n",
    "    input_height: Vertical size of expected input image to model.\n",
    "    input_depth: How many channels the expected input image should have.\n",
    "    input_mean: Pixel value that should be zero in the image for the graph.\n",
    "    input_std: How much to divide the pixel values by before recognition.\n",
    "  Returns:\n",
    "    The jpeg input layer and the distorted result tensor.\n",
    "  \"\"\"\n",
    "\n",
    "  jpeg_data = tf.placeholder(tf.string, name='DistortJPGInput')#placeholde for tf.gfile.FastGFile read string\n",
    "  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth) #\n",
    "  decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "  decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0) #变成4维\n",
    "  margin_scale = 1.0 + (random_crop / 100.0)\n",
    "  resize_scale = 1.0 + (random_scale / 100.0)\n",
    "  margin_scale_value = tf.constant(margin_scale)\n",
    "  resize_scale_value = tf.random_uniform(tensor_shape.scalar(),\n",
    "                                         minval=1.0,\n",
    "                                         maxval=resize_scale)\n",
    "  scale_value = tf.multiply(margin_scale_value, resize_scale_value)\n",
    "  precrop_width = tf.multiply(scale_value, input_width)\n",
    "  precrop_height = tf.multiply(scale_value, input_height)\n",
    "  precrop_shape = tf.stack([precrop_height, precrop_width])\n",
    "  precrop_shape_as_int = tf.cast(precrop_shape, dtype=tf.int32)\n",
    "  precropped_image = tf.image.resize_bilinear(decoded_image_4d,\n",
    "                                              precrop_shape_as_int)\n",
    "  precropped_image_3d = tf.squeeze(precropped_image, squeeze_dims=[0])\n",
    "  cropped_image = tf.random_crop(precropped_image_3d,\n",
    "                                 [input_height, input_width, input_depth])\n",
    "  if flip_left_right:\n",
    "    flipped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "  else:\n",
    "    flipped_image = cropped_image\n",
    "  brightness_min = 1.0 - (random_brightness / 100.0)\n",
    "  brightness_max = 1.0 + (random_brightness / 100.0)\n",
    "  brightness_value = tf.random_uniform(tensor_shape.scalar(),\n",
    "                                       minval=brightness_min,\n",
    "                                       maxval=brightness_max)\n",
    "  brightened_image = tf.multiply(flipped_image, brightness_value)\n",
    "  offset_image = tf.subtract(brightened_image, input_mean)\n",
    "  mul_image = tf.multiply(offset_image, 1.0 / input_std)\n",
    "  distort_result = tf.expand_dims(mul_image, 0, name='DistortResult')\n",
    "  return jpeg_data, distort_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. 生成一个tensor的summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入一个tensor，得到其4个summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. 定义分类层，返回分类层的重要op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在inception-v3(或者Mobilenet)模型的bottleneck层后面加上一个全连接分类层。所以需要输入bottleneck_tensor，以及其大小：bottleneck_tensor_size；final_tensor_name是添加的分类层的softmax层的名称；class_count用来定义ground_truth_input这个placeholde的size。中间也定义了许多summary\n",
    "返回：\n",
    "(1)分类层的train_Step(optimizer)；\n",
    "(2)损失函数：cross_entropy_mean；\n",
    "(3)由bottleneck_tensor得到的bottleneck_input [None, bottleneck_tensor_size]; \n",
    "(4)定义的ground_truth_input [None, class_count]；\n",
    "(5)以及final_tensor, softmax output\n",
    " #根据bottleneck_tensor返回新加层的运算op和placeholder\n",
    " #bottleneck_input 是输入placeholder[None, bottleneck_tensor_size(2048 or 1001)]\n",
    " #ground_truth_input 是输入placeholder[None, len(image_lists.keys())=5]\n",
    " #cross_entropy 是损失函数，需要上述两个placeholder输入的数据；\n",
    " #train_step 是cross_entropy的优化op；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor,\n",
    "                           bottleneck_tensor_size):\n",
    "  \"\"\"Adds a new softmax and fully-connected layer for training.\n",
    "  We need to retrain the top layer to identify our new classes, so this function\n",
    "  adds the right operations to the graph, along with some variables to hold the\n",
    "  weights, and then sets up all the gradients for the backward pass.\n",
    "  The set up for the softmax and fully-connected layers is based on:\n",
    "  https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html\n",
    "  Args:\n",
    "    class_count: Integer of how many categories of things we're trying to\n",
    "    recognize.\n",
    "    final_tensor_name: Name string for the new final node that produces results.\n",
    "    bottleneck_tensor: The output of the main CNN graph.\n",
    "    bottleneck_tensor_size: How many entries in the bottleneck vector.\n",
    "  Returns:\n",
    "    The tensors for the training and cross entropy results, and tensors for the\n",
    "    bottleneck input and ground truth input.\n",
    "  \"\"\"\n",
    "  with tf.name_scope('input'):\n",
    "    bottleneck_input = tf.placeholder_with_default(\n",
    "        bottleneck_tensor,\n",
    "        shape=[None, bottleneck_tensor_size],\n",
    "        name='BottleneckInputPlaceholder')\n",
    "\n",
    "    ground_truth_input = tf.placeholder(tf.float32,\n",
    "                                        [None, class_count],\n",
    "                                        name='GroundTruthInput')\n",
    "\n",
    "  # Organizing the following ops as `final_training_ops` so they're easier\n",
    "  # to see in TensorBoard\n",
    "  layer_name = 'final_training_ops'\n",
    "  with tf.name_scope(layer_name):\n",
    "    with tf.name_scope('weights'):\n",
    "      initial_value = tf.truncated_normal(\n",
    "          [bottleneck_tensor_size, class_count], stddev=0.001)\n",
    "\n",
    "      layer_weights = tf.Variable(initial_value, name='final_weights')\n",
    "\n",
    "      variable_summaries(layer_weights)\n",
    "    with tf.name_scope('biases'):\n",
    "      layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "      variable_summaries(layer_biases)\n",
    "    with tf.name_scope('Wx_plus_b'):\n",
    "      logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "      tf.summary.histogram('pre_activations', logits)\n",
    "\n",
    "  final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "  tf.summary.histogram('activations', final_tensor)\n",
    "\n",
    "  with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=ground_truth_input, logits=logits)\n",
    "    with tf.name_scope('total'):\n",
    "      cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "  tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "  with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)\n",
    "    train_step = optimizer.minimize(cross_entropy_mean)\n",
    "\n",
    "  return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,\n",
    "          final_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. 定义函数对比预测值与ground_truth，返回准确率和预测值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数是作为测试和验证存在的；result_tensor是add_final_training_ops返回的final_tensor，也就是softmax(logits)；返回prediction是分类层的预测值argmax, evaluation_step是得到准确率的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "  \"\"\"Inserts the operations we need to evaluate the accuracy of our results.\n",
    "  Args:\n",
    "    result_tensor: The new final node that produces results.\n",
    "    ground_truth_tensor: The node we feed ground truth data\n",
    "    into.\n",
    "  Returns:\n",
    "    Tuple of (evaluation step, prediction).\n",
    "  \"\"\"\n",
    "  with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "      prediction = tf.argmax(result_tensor, 1)\n",
    "      correct_prediction = tf.equal(\n",
    "          prediction, tf.argmax(ground_truth_tensor, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "      evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  tf.summary.scalar('accuracy', evaluation_step)\n",
    "  return evaluation_step, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. 将重新训练后的模型保存成二进制文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将模型保存成二进制文件，首先转化成了constant; 然后将inception和添加的分类层都保存近了模型，84M; 注意这里有一个隐含参数，FLAGS.final_tensor_name，默认是 “final_result”， 目前还不清楚这个final tensor是做什么用的; 看代码发现这个FLAGS.final_tensor_name被add_final_training_ops应用到final_tensor=softmax(logits)，也就是最后的分类预测层，考虑是保存成二进制后又留下接口，这样的话是不是可以在保存的时候多留几个接口，以上只是我的猜测，附上api：https://www.tensorflow.org/api_docs/python/tf/graph_util/convert_variables_to_constants\n",
    "参数：sess 当前的sess； graph 当前的计算图；graph_file_name 保存成的图像名称；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_graph_to_file(sess, graph, graph_file_name):\n",
    "  output_graph_def = graph_util.convert_variables_to_constants(\n",
    "      sess, graph.as_graph_def(), [FLAGS.final_tensor_name])\n",
    "  with gfile.FastGFile(graph_file_name, 'wb') as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. 为summary准备路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若/tmp/retain_dir 存在就删掉重新保存，若要保存中间的训练过程而不只是只保存最终结果就创建folder /tmp/intermediate_out_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_file_system():\n",
    "  # Setup the directory we'll write summaries to for TensorBoard\n",
    "  if tf.gfile.Exists(FLAGS.summaries_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.summaries_dir)\n",
    "  tf.gfile.MakeDirs(FLAGS.summaries_dir)\n",
    "  if FLAGS.intermediate_store_frequency > 0:\n",
    "    ensure_dir_exists(FLAGS.intermediate_output_graphs_dir)\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. 输入模型名称，返回模型的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型的信息，因为可以加载不同的模型，也就是通过architecture指定，\"inception_v3\" 或者 'mobilenet_something'; 以inception_v3模型为例的返回是：\n",
    " return {\n",
    "      'data_url': 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz',\n",
    "      'bottleneck_tensor_name': 'pool_3/_reshape:0',\n",
    "      'bottleneck_tensor_size': 2048,\n",
    "      'input_width': 299,\n",
    "      'input_height': 299,\n",
    "      'input_depth': 3,\n",
    "      'resized_input_tensor_name': 'Mul:0',\n",
    "      'model_file_name': 'classify_image_graph_def.pb',\n",
    "      'input_mean': 128,\n",
    "      'input_std': 128,\n",
    "  }\n",
    "  具体每一项都是干嘛的，还不清楚。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_info(architecture):\n",
    "  \"\"\"Given the name of a model architecture, returns information about it.\n",
    "  There are different base image recognition pretrained models that can be\n",
    "  retrained using transfer learning, and this function translates from the name\n",
    "  of a model to the attributes that are needed to download and train with it.\n",
    "  Args:\n",
    "    architecture: Name of a model architecture.\n",
    "  Returns:\n",
    "    Dictionary of information about the model, or None if the name isn't\n",
    "    recognized\n",
    "  Raises:\n",
    "    ValueError: If architecture name is unknown.\n",
    "  \"\"\"\n",
    "  architecture = architecture.lower()\n",
    "  if architecture == 'inception_v3':\n",
    "    # pylint: disable=line-too-long\n",
    "    data_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "    # pylint: enable=line-too-long\n",
    "    bottleneck_tensor_name = 'pool_3/_reshape:0'\n",
    "    bottleneck_tensor_size = 2048\n",
    "    input_width = 299\n",
    "    input_height = 299\n",
    "    input_depth = 3\n",
    "    resized_input_tensor_name = 'Mul:0'\n",
    "    model_file_name = 'classify_image_graph_def.pb'\n",
    "    input_mean = 128\n",
    "    input_std = 128\n",
    "  elif architecture.startswith('mobilenet_'):\n",
    "    parts = architecture.split('_')\n",
    "    if len(parts) != 3 and len(parts) != 4:\n",
    "      tf.logging.error(\"Couldn't understand architecture name '%s'\",\n",
    "                       architecture)\n",
    "      return None\n",
    "    version_string = parts[1]\n",
    "    if (version_string != '1.0' and version_string != '0.75' and\n",
    "        version_string != '0.50' and version_string != '0.25'):\n",
    "      tf.logging.error(\n",
    "          \"\"\"\"The Mobilenet version should be '1.0', '0.75', '0.50', or '0.25',\n",
    "  but found '%s' for architecture '%s'\"\"\",\n",
    "          version_string, architecture)\n",
    "      return None\n",
    "    size_string = parts[2]\n",
    "    if (size_string != '224' and size_string != '192' and\n",
    "        size_string != '160' and size_string != '128'):\n",
    "      tf.logging.error(\n",
    "          \"\"\"The Mobilenet input size should be '224', '192', '160', or '128',\n",
    " but found '%s' for architecture '%s'\"\"\",\n",
    "          size_string, architecture)\n",
    "      return None\n",
    "    if len(parts) == 3:\n",
    "      is_quantized = False\n",
    "    else:\n",
    "      if parts[3] != 'quantized':\n",
    "        tf.logging.error(\n",
    "            \"Couldn't understand architecture suffix '%s' for '%s'\", parts[3],\n",
    "            architecture)\n",
    "        return None\n",
    "      is_quantized = True\n",
    "    data_url = 'http://download.tensorflow.org/models/mobilenet_v1_'\n",
    "    data_url += version_string + '_' + size_string + '_frozen.tgz'\n",
    "    bottleneck_tensor_name = 'MobilenetV1/Predictions/Reshape:0'\n",
    "    bottleneck_tensor_size = 1001\n",
    "    input_width = int(size_string)\n",
    "    input_height = int(size_string)\n",
    "    input_depth = 3\n",
    "    resized_input_tensor_name = 'input:0'\n",
    "    if is_quantized:\n",
    "      model_base_name = 'quantized_graph.pb'\n",
    "    else:\n",
    "      model_base_name = 'frozen_graph.pb'\n",
    "    model_dir_name = 'mobilenet_v1_' + version_string + '_' + size_string\n",
    "    model_file_name = os.path.join(model_dir_name, model_base_name)\n",
    "    input_mean = 127.5\n",
    "    input_std = 127.5\n",
    "  else:\n",
    "    tf.logging.error(\"Couldn't understand architecture name '%s'\", architecture)\n",
    "    raise ValueError('Unknown architecture', architecture)\n",
    "\n",
    "  return {\n",
    "      'data_url': data_url,\n",
    "      'bottleneck_tensor_name': bottleneck_tensor_name,\n",
    "      'bottleneck_tensor_size': bottleneck_tensor_size,\n",
    "      'input_width': input_width,\n",
    "      'input_height': input_height,\n",
    "      'input_depth': input_depth,\n",
    "      'resized_input_tensor_name': resized_input_tensor_name,\n",
    "      'model_file_name': model_file_name,\n",
    "      'input_mean': input_mean,\n",
    "      'input_std': input_std,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. 根据模型信息预处理图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 将图像resize成[input_width, input_height, input_depth] -> [299, 299, 3], 这里就用到了上面的模型信息；\n",
    "(2) 将所有像素值减去input_mean: offset_image = resized_image - 128;\n",
    "(3) 归一化图像：mul_image = offset_image / 128.0；\n",
    "返回传入图像的placeholder: jpeg_data, 处理后的图像mul_image；\n",
    "函数16中的add_input_distortions的最后部分做了相同的事情，不同的是add_input_distortions还做了distortation操作；\n",
    "这个具体实现的时候可以作为预处理放在训练之外，比如用opencv实现pre_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_jpeg_decoding(input_width, input_height, input_depth, input_mean,\n",
    "                      input_std):\n",
    "  \"\"\"Adds operations that perform JPEG decoding and resizing to the graph..\n",
    "  Args:\n",
    "    input_width: Desired width of the image fed into the recognizer graph.\n",
    "    input_height: Desired width of the image fed into the recognizer graph.\n",
    "    input_depth: Desired channels of the image fed into the recognizer graph.\n",
    "    input_mean: Pixel value that should be zero in the image for the graph.\n",
    "    input_std: How much to divide the pixel values by before recognition.\n",
    "  Returns:\n",
    "    Tensors for the node to feed JPEG data into, and the output of the\n",
    "      preprocessing steps.\n",
    "  \"\"\"\n",
    "  jpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')#placeholder用来传入gfile string\n",
    "  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\n",
    "  decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "  decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "  resize_shape = tf.stack([input_height, input_width])\n",
    "  resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\n",
    "  resized_image = tf.image.resize_bilinear(decoded_image_4d,\n",
    "                                           resize_shape_as_int)\n",
    "  offset_image = tf.subtract(resized_image, input_mean)\n",
    "  mul_image = tf.multiply(offset_image, 1.0 / input_std)\n",
    "  return jpeg_data, mul_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. main函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  # Needed to make sure the logging output is visible.\n",
    "  # See https://github.com/tensorflow/tensorflow/issues/3047\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)# 确保tf.logging能输出\n",
    "\n",
    "  # Prepare necessary directories  that can be used during training\n",
    "  prepare_file_system() # 创建summary的路径\n",
    "\n",
    "  # Gather information about the model architecture we'll be using.\n",
    "  model_info = create_model_info(FLAGS.architecture)#输入模型名称，返回模型信息的字典\n",
    "  if not model_info:\n",
    "    tf.logging.error('Did not recognize architecture flag') #信息获取失败，返回\n",
    "    return -1\n",
    "\n",
    "  # Set up the pre-trained graph.\n",
    "  maybe_download_and_extract(model_info['data_url']) # 若模型没有在默认路径中，则下载并解压\n",
    "  # 根据模型信息和下载好的模型加载训练好的计算图，返回计算图，用来计算bottleneck和输入图像的两个tensor\n",
    "  graph, bottleneck_tensor, resized_image_tensor = (\n",
    "      create_model_graph(model_info))\n",
    "\n",
    "  # Look at the folder structure, and create lists of all the images.\n",
    "  image_lists = create_image_lists(FLAGS.image_dir, FLAGS.testing_percentage,\n",
    "                                   FLAGS.validation_percentage) #创建所有图像的字典，并按照testing和validation的百分比随机分\n",
    "  class_count = len(image_lists.keys()) # 分类的个数，label_name的个数\n",
    "  if class_count == 0:\n",
    "    tf.logging.error('No valid folders of images found at ' + FLAGS.image_dir)#分类个数为0说明没有正确组织结构\n",
    "    return -1\n",
    "  if class_count == 1:\n",
    "    tf.logging.error('Only one valid folder of images found at ' +\n",
    "                     FLAGS.image_dir +\n",
    "                     ' - multiple classes are needed for classification.')#分类个数为1，那么也没必要分类\n",
    "    return -1\n",
    "\n",
    "  # See if the command-line flags mean we're applying any distortions.\n",
    "    # 判断是否需要distort, 返回一个bool值\n",
    "  do_distort_images = should_distort_images(\n",
    "      FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n",
    "      FLAGS.random_brightness)\n",
    "  # 所以这里的graph就是上述加载好的与训练模型\n",
    "  with tf.Session(graph=graph) as sess:\n",
    "    # Set up the image decoding sub-graph.\n",
    "    # 新添加的两个tensor，一个用来传入jpeg string，另外一个是按照模型信息进行resize和归一化之后的图像tensor\n",
    "    # image_string_data ->feed-> jpeg_data_tensor -> decoded_image_tensor -> model -> bottleneck\n",
    "    jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(\n",
    "        model_info['input_width'], model_info['input_height'],\n",
    "        model_info['input_depth'], model_info['input_mean'],\n",
    "        model_info['input_std'])\n",
    "\n",
    "    if do_distort_images:\n",
    "      # We will be applying distortions, so setup the operations we'll need.\n",
    "      # 新添加两个tensor, 一个用来传入待变化的图像，一个保存图像变化后的结果，这个函数在图像变换后做了和add_jpeg_decoding一样的事情\n",
    "      # 将图像resize到模型需要的尺寸，返回一个接收图像string的distorted_jpeg_data_tensor，和变换和resize处理后的distorted_image_tensor\n",
    "      # 所以当需要随机变换图像时：\n",
    "      # image_string_data ->feed-> distorted_jpeg_data_tensor -> distorted_image_tensor -> \n",
    "      # ->feed-> resized_image_tensor -> bottleneck_tensor -> bottleneck\n",
    "      (distorted_jpeg_data_tensor,\n",
    "       distorted_image_tensor) = add_input_distortions(\n",
    "           FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n",
    "           FLAGS.random_brightness, model_info['input_width'],\n",
    "           model_info['input_height'], model_info['input_depth'],\n",
    "           model_info['input_mean'], model_info['input_std'])\n",
    "    else:\n",
    "      # We'll make sure we've calculated the 'bottleneck' image summaries and\n",
    "      # cached them on disk.\n",
    "      # 若不需要变化，对所有的上述按照模型信息进行resize和归一化后的图像进行bottleneck生成\n",
    "      # image_string_data ->feed-> jpeg_data_tensor -> decoded_image_tensor \n",
    "      # ->feed-> resized_image_tensor -> model -> bottleneck\n",
    "      cache_bottlenecks(sess, image_lists, FLAGS.image_dir,\n",
    "                        FLAGS.bottleneck_dir, jpeg_data_tensor,\n",
    "                        decoded_image_tensor, resized_image_tensor,\n",
    "                        bottleneck_tensor, FLAGS.architecture)\n",
    "\n",
    "    # Add the new layer that we'll be training.\n",
    "    # 根据bottleneck_tensor返回新加层的运算op和placeholder\n",
    "    # bottleneck_input 是输入placeholder[None, bottleneck_tensor_size(2048 or 1001)]\n",
    "    # ground_truth_input 是输入placeholder[None, len(image_lists.keys())=5]\n",
    "    # cross_entropy 是损失函数，需要上述两个placeholder输入的数据；\n",
    "    # train_step 是cross_entropy的优化op；\n",
    "    # final_tensor 是softmax(logits), 同样需要上述两个placeholder feed\n",
    "    (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n",
    "     final_tensor) = add_final_training_ops(\n",
    "         len(image_lists.keys()), FLAGS.final_tensor_name, bottleneck_tensor,\n",
    "         model_info['bottleneck_tensor_size'])\n",
    "\n",
    "    # Create the operations we need to evaluate the accuracy of our new layer.\n",
    "    # 输入预测输出final_tensor和ground_truth，比较两者计算正确率-> evaluation_step\n",
    "    # prediction是简单的argmax(final_tensor)\n",
    "    evaluation_step, prediction = add_evaluation_step(\n",
    "        final_tensor, ground_truth_input)\n",
    "\n",
    "    # Merge all the summaries and write them out to the summaries_dir\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n",
    "                                         sess.graph)\n",
    "\n",
    "    validation_writer = tf.summary.FileWriter(\n",
    "        FLAGS.summaries_dir + '/validation')\n",
    "\n",
    "    # Set up all our weights to their initial default values.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Run the training for as many cycles as requested on the command line.\n",
    "    # 训练过程开始，迭代how_many_training_steps＝4000次\n",
    "    for i in range(FLAGS.how_many_training_steps):\n",
    "      # Get a batch of input bottleneck values, either calculated fresh every\n",
    "      # time with distortions applied, or from the cache stored on disk.\n",
    "      if do_distort_images:\n",
    "        # 如果需要变化图像，就需要先变化再重新生成bottleneck组成train_bottlenecks 和 train_ground_truth\n",
    "        (train_bottlenecks,\n",
    "         train_ground_truth) = get_random_distorted_bottlenecks(\n",
    "             sess, image_lists, FLAGS.train_batch_size, 'training',\n",
    "             FLAGS.image_dir, distorted_jpeg_data_tensor,\n",
    "             distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n",
    "      else:\n",
    "        # 如果不需要变换图像，则读取预先生成的bottlenecks\n",
    "        (train_bottlenecks,\n",
    "         train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "             sess, image_lists, FLAGS.train_batch_size, 'training',\n",
    "             FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "             decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "             FLAGS.architecture)\n",
    "      # Feed the bottlenecks and ground truth into the graph, and run a training\n",
    "      # step. Capture training summaries for TensorBoard with the `merged` op.\n",
    "      train_summary, _ = sess.run(\n",
    "          [merged, train_step],\n",
    "          feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                     ground_truth_input: train_ground_truth})\n",
    "      train_writer.add_summary(train_summary, i)\n",
    "\n",
    "      # Every so often, print out how well the graph is training.\n",
    "      # 每隔10步输出训练准确率，训练损失，validation准确率\n",
    "      is_last_step = (i + 1 == FLAGS.how_many_training_steps)\n",
    "      if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "        train_accuracy, cross_entropy_value = sess.run(\n",
    "            [evaluation_step, cross_entropy],\n",
    "            feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                       ground_truth_input: train_ground_truth})\n",
    "        tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\n",
    "                        (datetime.now(), i, train_accuracy * 100))\n",
    "        tf.logging.info('%s: Step %d: Cross entropy = %f' %\n",
    "                        (datetime.now(), i, cross_entropy_value))\n",
    "        validation_bottlenecks, validation_ground_truth, _ = (\n",
    "            get_random_cached_bottlenecks(\n",
    "                sess, image_lists, FLAGS.validation_batch_size, 'validation',\n",
    "                FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "                decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "                FLAGS.architecture))\n",
    "        # Run a validation step and capture training summaries for TensorBoard\n",
    "        # with the `merged` op.\n",
    "        validation_summary, validation_accuracy = sess.run(\n",
    "            [merged, evaluation_step],\n",
    "            feed_dict={bottleneck_input: validation_bottlenecks,\n",
    "                       ground_truth_input: validation_ground_truth})\n",
    "        validation_writer.add_summary(validation_summary, i)\n",
    "        tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                        (datetime.now(), i, validation_accuracy * 100,\n",
    "                         len(validation_bottlenecks)))\n",
    "\n",
    "      # Store intermediate results\n",
    "      intermediate_frequency = FLAGS.intermediate_store_frequency\n",
    "    \n",
    "      # 如果想每隔intermediate_frequency步保存一下模型，指定intermediate_frequency一个大于0的值即可；\n",
    "      if (intermediate_frequency > 0 and (i % intermediate_frequency == 0)\n",
    "          and i > 0):\n",
    "        intermediate_file_name = (FLAGS.intermediate_output_graphs_dir +\n",
    "                                  'intermediate_' + str(i) + '.pb')\n",
    "        tf.logging.info('Save intermediate result to : ' +\n",
    "                        intermediate_file_name)\n",
    "        save_graph_to_file(sess, graph, intermediate_file_name)\n",
    "\n",
    "    # We've completed all our training, so run a final test evaluation on\n",
    "    # some new images we haven't used before.\n",
    "    # 全部训练完毕，获取全部的testing bottlenecks 测试准确率。\n",
    "    test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "        get_random_cached_bottlenecks(\n",
    "            sess, image_lists, FLAGS.test_batch_size, 'testing',\n",
    "            FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "            decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "            FLAGS.architecture))\n",
    "    test_accuracy, predictions = sess.run(\n",
    "        [evaluation_step, prediction],\n",
    "        feed_dict={bottleneck_input: test_bottlenecks,\n",
    "                   ground_truth_input: test_ground_truth})\n",
    "    tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n",
    "                    (test_accuracy * 100, len(test_bottlenecks)))\n",
    "    # 定义是否输出错误分类的图像名称\n",
    "    if FLAGS.print_misclassified_test_images:\n",
    "      tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\n",
    "      for i, test_filename in enumerate(test_filenames):\n",
    "        if predictions[i] != test_ground_truth[i].argmax():\n",
    "          tf.logging.info('%70s  %s' %\n",
    "                          (test_filename,\n",
    "                           list(image_lists.keys())[predictions[i]]))\n",
    "\n",
    "    # Write out the trained graph and labels with the weights stored as\n",
    "    # constants.\n",
    "    save_graph_to_file(sess, graph, FLAGS.output_graph)\n",
    "    with gfile.FastGFile(FLAGS.output_labels, 'w') as f:\n",
    "      f.write('\\n'.join(image_lists.keys()) + '\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
